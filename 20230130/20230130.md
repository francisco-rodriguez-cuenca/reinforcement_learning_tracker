# Notes on RL 5

https://arxiv.org/search/advanced?advanced=&terms-0-operator=AND&terms-0-term=%22Reinforcement+Learning%22&terms-0-field=all&classification-physics_archives=all&classification-include_cross_list=include&date-year=&date-filter_by=date_range&date-from_date=2023-01-23&date-to_date=2023-01-30&date-date_type=submitted_date&abstracts=show&size=200&order=-announced_date_first
__95 papers__

## Things to read

* Something About RLHF

## New papers

1. __Engineering Applications__
   1. Networks
      1. [Privacy-Aware Load Balancing in Fog Networks: A Reinforcement Learning Approach](https://arxiv.org/pdf/2301.09497.pdf)
      2. [Forecaster-aided User Association and Load Balancing in Multi-band Mobile Networks](https://arxiv.org/pdf/2301.09294.pdf)
      3. [Digital Twin-Based Multiple Access Optimization and Monitoring via Model-Driven Bayesian Learning](https://arxiv.org/pdf/2210.05582.pdf)
   2. Vehicular Edge Computing
      1. [Cooperative Sensing and Uploading for Quality-Cost Tradeoff of Digital Twins in VEC](https://arxiv.org/pdf/2210.17386.pdf)
      2. [Cooperative Sensing and Heterogeneous Information Fusion in VCPS: A Multi-agent Deep Reinforcement Learning Approach](https://arxiv.org/pdf/2209.12265.pdf)
   3. Image
      1. [SNeRL: Semantic-aware Neural Radiance Fields for Reinforcement Learning](https://arxiv.org/pdf/2301.11520.pdf)
      2. [AccDecoder: Accelerated Decoding for Neural-enhanced Video Analytics](https://arxiv.org/pdf/2301.08664.pdf)
   4. Energy
      1. [Exploring Deep Reinforcement Learning for Holistic Smart Building Control](https://arxiv.org/pdf/2301.11510.pdf)
      2. [Optimal Inter-area Oscillation Damping Control: A Transfer Deep Reinforcement Learning Approach with Switching Control Strategy](https://arxiv.org/pdf/2301.09321.pdf)
   5. Navigation
      1. [Modeling human road crossing decisions as reward maximization with visual perception limitations](https://arxiv.org/pdf/2301.11737.pdf)รง
      2. [ARiADNE: A Reinforcement learning approach using Attention-based Deep Networks for Exploration](https://arxiv.org/pdf/2301.11575.pdf)
      3. [Double Deep Reinforcement Learning Techniques for Low Dimensional Sensing Mapless Navigation of Terrestrial Mobile Robots](https://arxiv.org/pdf/2301.11173.pdf)
      4. [Predicting Parameters for Modeling Traffic Participants](https://arxiv.org/pdf/2301.10893.pdf)
      5. [Autonomous particles](https://arxiv.org/pdf/2301.10077.pdf)
      6. [A deep reinforcement learning approach to assess the low-altitude airspace capacity for urban air mobility](https://arxiv.org/pdf/2301.09758.pdf)
   6. Robotics
      1. [DreamWaQ: Learning Robust Quadrupedal Locomotion With Implicit Terrain Imagination via Deep Reinforcement Learning](https://arxiv.org/pdf/2301.10602.pdf)
      2. [Constrained Reinforcement Learning for Dexterous Manipulation](https://arxiv.org/pdf/2301.09766.pdf)
      3. [Deep Reinforcement Learning for Concentric Tube Robot Path Planning](https://arxiv.org/pdf/2301.09162.pdf)
   7. Job Scheduling
      1. [Two-Stage Learning For the Flexible Job Shop Scheduling Problem](https://arxiv.org/pdf/2301.09703.pdf)
   8. Neural Networks
   9. Others
2. __Physics Applications__
   1. [Deep reinforcement learning for turbulent drag reduction in channel flows](https://arxiv.org/pdf/2301.09889.pdf)
3. __Recommender Systems__
   1. [Generative Slate Recommendation with Reinforcement Learning v2](https://arxiv.org/pdf/2301.08632.pdf)
4. __Reinforcement Learning Theory__
   1. Reinforcement Learning from Human Preferences
      1. [Reinforcement Learning from Diverse Human Preferences](https://arxiv.org/pdf/2301.11774.pdf)
      2. [An Incremental Inverse Reinforcement Learning Approach for Motion Planning with Human Preferences](https://arxiv.org/pdf/2301.10528.pdf)
   2. Policy optimization
      1. [Behaviour Discriminator: A Simple Data Filtering Method to Improve Offline Policy Learning](https://arxiv.org/pdf/2301.11734.pdf)
      2. [Generalized Munchausen Reinforcement Learning using Tsallis KL Divergence](https://arxiv.org/pdf/2301.11476.pdf)
      3. [Model-based Offline Reinforcement Learning with Local Misspecification](https://arxiv.org/pdf/2301.11426.pdf)
      4. [Trajectory-Aware Eligibility Traces for Off-Policy Reinforcement Learning](https://arxiv.org/pdf/2301.11321.pdf)
      5. [Which Experiences Are Influential for Your Agent? Policy Iteration with Turn-over Dropout](https://arxiv.org/pdf/2301.11168.pdf)
      6. [On The Convergence Of Policy Iteration-Based Reinforcement Learning With Monte Carlo Policy Evaluation](https://arxiv.org/pdf/2301.09709.pdf)
      7. [Variance-Reduced Conservative Policy Iteration](https://arxiv.org/pdf/2212.06283.pdf)
      8. [Normality-Guided Distributional Reinforcement Learning for Continuous Control](https://arxiv.org/pdf/2208.13125.pdf)
   3. Risk-sensitive/safe/constrained RL
      1. [On the Global Convergence of Risk-Averse Policy Gradient Methods with Dynamic Time-Consistent Risk Measures](https://arxiv.org/pdf/2301.10932.pdf)
      2. [Efficient Trust Region-Based Safe Reinforcement Learning with Low-Bias Distributional Actor-Critic](https://arxiv.org/pdf/2301.10923.pdf)
      3. [AutoCost: Evolving Intrinsic Cost for Zero-violation Reinforcement Learning](https://arxiv.org/pdf/2301.10339.pdf)
      4. [Solving Constrained Reinforcement Learning through Augmented State and Reward Penalties](https://arxiv.org/pdf/2301.11592.pdf)
      5. [Learning Policies with Zero or Bounded Constraint Violation for Constrained MDPs](https://arxiv.org/pdf/2106.02684.pdf)
   4. Robust RL
      1. [Single-Trajectory Distributionally Robust Reinforcement Learning](https://arxiv.org/pdf/2301.11721.pdf)
      2. [Train Hard, Fight Easy: Robust Meta Reinforcement Learning](https://arxiv.org/pdf/2301.11147.pdf)
      3. [Causal Counterfactuals for Improving the Robustness of Reinforcement Learning](https://arxiv.org/pdf/2211.05551.pdf)
      4. [Distributionally Robust Offline Reinforcement Learning with Linear Function Approximation v3](https://arxiv.org/pdf/2209.06620.pdf)
   5. Reviews
      1. [Intrinsic Motivation in Model-based Reinforcement Learning: A Brief Review](https://arxiv.org/pdf/2301.10067.pdf)
   6. Episodic Control
      1. [Neural Episodic Control with State Abstraction](https://arxiv.org/pdf/2301.11490.pdf)
   7. Regret Minimization
      1. [Collaborative Regret Minimization in Multi-Armed Bandits](https://arxiv.org/pdf/2301.11442.pdf)   
   8. Exploration Methods
      1. [Deep Laplacian-based Options for Temporally-Extended Exploration](https://arxiv.org/pdf/2301.11181.pdf)
   9. Multi-Agent
      1. [Multi-Agent congestion cost minimization with linear function approximation](https://arxiv.org/pdf/2301.10993.pdf)
      2. [Distributed Control of Partial Differential Equations Using Convolutional Reinforcement Learning](https://arxiv.org/pdf/2301.10737.pdf)
      3. [Discriminative Experience Replay for Efficient Multi-agent Reinforcement Learning](https://arxiv.org/pdf/2301.10574.pdf)
      4. [Asymptotic Convergence and Performance of Multi-Agent Q-learning Dynamics](https://arxiv.org/pdf/2301.09619.pdf)
      5. [An Energy-aware, Fault-tolerant, and Robust Deep Reinforcement Learning based approach for Multi-agent Patrolling Problems.](https://arxiv.org/pdf/2212.08230.pdf)
      6. [Multi-Agent Deep Reinforcement Learning for Efficient Passenger Delivery in Urban Air Mobility](https://arxiv.org/pdf/2211.06890.pdf)
   10. Reward optimization
       1. [Automatic Intrinsic Reward Shaping for Exploration in Deep Reinforcement Learning](https://arxiv.org/pdf/2301.10886.pdf)
   11. Automated planning
       1. [NeSIG: A Neuro-Symbolic Method for Learning to Generate Planning Problems](https://arxiv.org/pdf/2301.10280.pdf)
       2. [Effective Baselines for Multiple Object Rearrangement Planning in Partially Observable Mapped Environments](https://arxiv.org/pdf/2301.09854.pdf)
       3. [PushWorld: A benchmark for manipulation planning with tools and movable obstacles](https://arxiv.org/pdf/2301.10289.pdf)
       4. [Efficient Planning in a Compact Latent Action Space](https://arxiv.org/pdf/2208.10291.pdf)
       5. [Provably Efficient Causal Model-Based Reinforcement Learning for Systematic Generalization](https://arxiv.org/pdf/2202.06545.pdf)
   12. Explainable Reinforcement Learning
       1. [ASQ-IT: Interactive Explanations for Reinforcement-Learning Agents](https://arxiv.org/pdf/2301.09941.pdf)
       2. [Explainable Deep Reinforcement Learning: State of the Art and Challenges](https://arxiv.org/pdf/2301.09937.pdf)
       3. [Experiential Explanations for Reinforcement Learning](https://arxiv.org/pdf/2210.04723.pdf)
   13. Transformers
       1. [SMART: Self-supervised Multi-task pretrAining with contRol Transformers](https://arxiv.org/pdf/2301.09816.pdf)
       2. [Learning to View: Decision Transformers for Active Object Detection](https://arxiv.org/pdf/2301.09544.pdf)
       3. [ReInform: Selecting paths with reinforcement learning for contextualized link prediction](https://arxiv.org/pdf/2211.10688.pdf)
   14. Lifelong RL
       1. [Lifelong Reinforcement Learning with Modulating Masks](https://arxiv.org/pdf/2212.11110.pdf)
   15. Offline RL
       1. [On Instance-Dependent Bounds for Offline Reinforcement Learning with Linear Function Approximation](https://arxiv.org/pdf/2211.13208.pdf)
       2. [User-Interactive Offline Reinforcement Learning](https://arxiv.org/pdf/2205.10629.pdf)
   16. Multi-task Imitation Learning
       1. [A Context-based Multi-task Hierarchical Inverse Reinforcement Learning Algorithm](https://arxiv.org/pdf/2210.01969.pdf)
   17. Convex RL
       1. [Challenging Common Assumptions in Convex Reinforcement Learning](https://arxiv.org/pdf/2202.01511.pdf)
   18. Others
       1. [Demystifying Reinforcement Learning in Time-Varying Systems](https://arxiv.org/pdf/2201.05560.pdf)
       2. [A Boosting Approach to Reinforcement Learning](https://arxiv.org/pdf/2108.09767.pdf)
       3. [Regret Analysis of Learning-Based MPC with Partially-Unknown Cost Function](https://arxiv.org/pdf/2108.02307.pdf)
    19. Evolutionary Learning
        1. [Truthful Self-Play v5](https://arxiv.org/pdf/2106.03007.pdf)
    20. Goal-conditioned/Curriculum RL
        1. [Outcome-directed Reinforcement Learning by Uncertainty \& Temporal Distance-Aware Curriculum Goal Generation](https://arxiv.org/pdf/2301.11741.pdf)
5. __Reinforcement Learning with Human Feedback__
   1. [Principled Reinforcement Learning with Human Feedback from Pairwise or K-wise Comparisons](https://arxiv.org/pdf/2301.11270.pdf)
6. __Legal Applications__
   1. [Large Language Models as Fiduciaries](https://arxiv.org/pdf/2301.10095.pdf)
7. __Financial Applications__
   1. [A Deep Neural Network Algorithm for Linear-Quadratic Portfolio Optimization with MGARCH and Small Transaction Costs](https://arxiv.org/pdf/2301.10869.pdf)
   2. [Select and Trade: Towards Unified Pair Trading with Hierarchical Reinforcement Learning](https://arxiv.org/pdf/2301.10724.pdf)
   3. [Exploring local effects of economic activities using agent-based ecosystem models](https://arxiv.org/pdf/2301.10507.pdf)
   4. [Stock Trading Optimization through Model-based Reinforcement Learning with Normalizing Flows](https://arxiv.org/pdf/2301.09297.pdf)
   5. [Predictive Crypto-Asset Automated Market Making Architecture for Decentralized Finance using Deep Reinforcement Learning](https://arxiv.org/pdf/2211.01346.pdf)
8. __Human-agent interaction__
   1. [Story Shaping: Teaching Agents Human-like Behavior with Stories](https://arxiv.org/pdf/2301.10107.pdf)
9. __Game Theory__
    1. [A Game-Theoretic Framework for Managing Risk in Multi-Agent Systems](https://arxiv.org/pdf/2205.15434.pdf)
10. __Biology__
    1. [A numerical simulation method of fish adaption behavior based on deep reinforcement learning and fluid-structure coupling โ realization of some lateral line functions](https://arxiv.org/pdf/2301.10085.pdf)
11. __Federated Learning__
    1. [FedHQL: Federated Heterogeneous Q-Learning](https://arxiv.org/pdf/2301.11135.pdf)
    2. [Privacy-Preserving Joint Edge Association and Power Optimization for the Internet of Vehicles via Federated Multi-Agent Reinforcement Learning](https://arxiv.org/pdf/2301.11014.pdf)
12. __Natural Language Processing__
    1. [Intrinsically Motivated Compositional Language Emergence](https://arxiv.org/pdf/2012.05011.pdf)
# Notes on RL 11

__45__ papers

Using arxiv scraper

## New papers

1. __Engineering Applications__
   1. Navigation
      1. [A multi-functional simulation platform for on-demand ride service operations](https://arxiv.org/pdf/2303.12336)
      2. [Adaptive Road Configurations for Improved Autonomous Vehicle-Pedestrian Interactions using Reinforcement Learning](https://arxiv.org/pdf/2303.12289)
      3. [Autonomous Blimp Control via H-infinity Robust Deep Residual Reinforcement Learning](https://arxiv.org/pdf/2303.13929)
      4. [Deep Reinforcement Learning for Localizability-Enhanced Navigation in Dynamic Human Environments](https://arxiv.org/pdf/2303.12354)
      5. [RLOR: A Flexible Framework of Deep Reinforcement Learning for Operation Research](https://arxiv.org/pdf/2303.13117)
      6. [SACPlanner: Real-World Collision Avoidance with a Soft Actor Critic Local Planner and Polar State Representations](https://arxiv.org/pdf/2303.11801)
   2. Networks
      1. [Beam Management Driven by Radio Environment Maps in O-RAN Architecture](https://arxiv.org/pdf/2303.11742)
      2. [Deep Reinforcement Learning for Distributed Dynamic Coordinated Beamforming in Massive MIMO Cellular Networks](https://arxiv.org/pdf/2303.14082)
      3. "[Distributed Two-tier DRL Framework for Cell-Free Network: Association, Beamforming and Power Allocation](https://arxiv.org/pdf/2303.12479)
      4. [Generative AI-aided Optimization for AI-Generated Content (AIGC) Services in Edge Networks](https://arxiv.org/pdf/2303.13052)
      5. [HAPS-UAV-Enabled Heterogeneous Networks: A Deep Reinforcement Learning Approach](https://arxiv.org/pdf/2303.12883)
      6. [Multi-agent Reinforcement Learning for Regional Signal control in Large-scale Grid Traffic network](https://arxiv.org/pdf/2303.11899)
      7. [Stochastic Graph Neural Network-based Value Decomposition for MARL in Internet of Vehicles](https://arxiv.org/pdf/2303.13213)
   3.  Robotics
       1.  [NeuronsMAE: A Novel Multi-Agent Reinforcement Learning Environment for Cooperative and Competitive Multi-Robot Tasks](https://arxiv.org/pdf/2303.12319)
       2.  [QDP: Learning to Sequentially Optimise Quasi-Static and Dynamic Manipulation Primitives for Robotic Cloth Manipulation](https://arxiv.org/pdf/2303.13320)
       3.  [Rotating without Seeing: Towards In-hand Dexterity through Touch](https://arxiv.org/pdf/2303.10880)
2. __Reinforcement Learning Theory__
    1. Automated planning
        1.  [EDGI: Equivariant Diffusion for Planning with Embodied Agents](https://arxiv.org/pdf/2303.12410)
    2.  Exploration Methods
        1.  [Planning Goals for Exploration](https://arxiv.org/pdf/2303.13002)
    3.  Goal-conditioned
        1.  [Imitating Graph-Based Planning with Goal-Conditioned Policies](https://arxiv.org/pdf/2303.11166)
    4.  Hierarchical RL
        1.  [A Hierarchical Hybrid Learning Framework for Multi-agent Trajectory Prediction](https://arxiv.org/pdf/2303.12274)
    5.  Imitation / Inverse / Demonstration Reinforcement Learning
        1.  [A Survey of Demonstration Learning](https://arxiv.org/pdf/2303.11191) INT INT
        2.  [Boosting Reinforcement Learning and Planning with Demonstrations: A Survey](https://arxiv.org/pdf/2303.13489) INT INT
        3.  [Bridging Imitation and Online Reinforcement Learning: An Optimistic Tale](https://arxiv.org/pdf/2303.11369) INT
    6.  Markov Decision Processes / Deep Theory
        1.  [Connected Superlevel Set in (Deep) Reinforcement Learning and its Application to Minimax Theorems](https://arxiv.org/pdf/2303.12981)
        2.  [Hardness of Independent Learning and Sparse Equilibrium Computation in Markov Games](https://arxiv.org/pdf/2303.12287)
        3.  [Inexact iterative numerical linear algebra for neural network-based spectral estimation and rare-event prediction](https://arxiv.org/pdf/2303.12534)
        4.  [Matryoshka Policy Gradient for Entropy-Regularized RL: Convergence and Global Optimality](https://arxiv.org/pdf/2303.12785)
        5.  [Policy Evaluation in Distributional LQR](https://arxiv.org/pdf/2303.13657)
        6.  [Reinforcement Learning with Exogenous States and Rewards](https://arxiv.org/pdf/2303.12957)
        7.  [Strategy Synthesis in Markov Decision Processes Under Limited Sampling Access](https://arxiv.org/pdf/2303.12718)
        8.  [Wasserstein Auto-encoded MDPs: Formal Verification of Efficiently Distilled RL Policies with Many-sided Guarantees](https://arxiv.org/pdf/2303.12558)
    7.  Multi-Task
        1.  [Multi-Task Reinforcement Learning in Continuous Control with Successor Feature-Based Concurrent Composition](https://arxiv.org/pdf/2303.13935)
    8.  Offline RL
        1.  [Optimal Transport for Offline Imitation Learning](https://arxiv.org/pdf/2303.13971)
    9.  Risk-sensitive/safe/constrained RL
        1.  [Bridging Transient and Steady-State Performance in Voltage Control: A Reinforcement Learning Approach with Safe Gradient Flow](https://arxiv.org/pdf/2303.11417)
    10. Reward Optimization
        1.  [Learning Reward Machines in Cooperative Multi-Agent Tasks](https://arxiv.org/pdf/2303.14061)
    11. Time-Series Learning
        1.  "[Style Miner: Find Significant and Stable Explanatory Factors in Time Series with Constrained Reinforcement Learning](https://arxiv.org/pdf/2303.11716) INT
    12. Transformers
        1.  [: Transferring Visual Representations for Reinforcement Learning via Prompting](https://arxiv.org/pdf/2303.12371)
3. __Game Theory__
   1. [CH-Go: Online Go System Based on Chunk Data Storage](https://arxiv.org/pdf/2303.13553)
4.  __Healthcare Applications__
    1.  [Policy Optimization for Personalized Interventions in Behavioral Health](https://arxiv.org/pdf/2303.12206)
    2.  [Synthetic Health-related Longitudinal Data with Mixed-type Variables Generated using Diffusion Models](https://arxiv.org/pdf/2303.12281)
5.  __Natural Language Processing__
    1.  [Can we trust the evaluation on ChatGPT?](https://arxiv.org/pdf/2303.12767) INT
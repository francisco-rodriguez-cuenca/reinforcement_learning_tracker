# Notes on RL 17

__58__ papers + __129__

Using arxiv scraper

## New papers

1. __Engineering Applications__
   1. Agriculture
      1. [Heterogeneous GNN-RL Based Task Offloading for UAV-aided Smart Agriculture](https://arxiv.org/pdf/2305.02112)
   3. Computing and Software Engineering
      1. [Optimizing Memory Mapping Using Deep Reinforcement Learning](https://arxiv.org/pdf/2305.07440)
      2. [RLocator: Reinforcement Learning for Bug Localization](https://arxiv.org/pdf/2305.05586)
      3. [Reducing Idleness in Financial Cloud via Multi-objective Evolutionary Reinforcement Learning based Load Balancer](https://arxiv.org/pdf/2305.03463)
   4. Cyber Security 
      1. [Greybox Penetration Testing on Cloud Access Control with IAM Modeling and Deep Reinforcement Learning](https://arxiv.org/pdf/2304.14540)
      2. [Model Extraction Attacks Against Reinforcement Learning Based Controllers](https://arxiv.org/pdf/2304.13090)
      3. [Multi-criteria Hardware Trojan Detection: A Reinforcement Learning Approach](https://arxiv.org/pdf/2304.13232)
      4. [HoneyIoT: Adaptive High-Interaction Honeypot for IoT Devices Through Reinforcement Learning](https://arxiv.org/pdf/2305.06430)
      5. [Mastering Percolation-like Games with Deep Learning](https://arxiv.org/pdf/2305.07687)
   5. Cyber Operations (CyOps)
   6. Energy
      1. [Optimal Scheduling in IoT-Driven Smart Isolated Microgrids Based on Deep Reinforcement Learning](https://arxiv.org/pdf/2305.00127)
      2. [Optimizing Energy Efficiency in Metro Systems Under Uncertainty Disturbances Using Reinforcement Learning](https://arxiv.org/pdf/2304.13443)
      3. [ReLBOT: A Transfer Learning Approach to Minimize Reinforcement Learning Risks in Smart Buildings](https://arxiv.org/pdf/2305.00365)
      4. [A Deep Reinforcement Learning-based Reserve Optimization in Active Distribution Systems for Tertiary Frequency Regulation](https://arxiv.org/pdf/2305.04163)
      5. [An Improved Yaw Control Algorithm for Wind Turbines via Reinforcement Learning](https://arxiv.org/pdf/2305.01299)
      6. [Assessment of Reinforcement Learning Algorithms for Nuclear Power Plant Fuel Optimization](https://arxiv.org/pdf/2305.05812)
      7. [Mixed-Integer Optimal Control via Reinforcement Learning: A Case Study on Hybrid Vehicle Energy Management](https://arxiv.org/pdf/2305.01461)
      8. [Optimal Energy System Scheduling Using A Constraint-Aware Reinforcement Learning Algorithm](https://arxiv.org/pdf/2305.05484)
   7. Environment
   8. Image & Video
      1. [ALL-E: Aesthetics-guided Low-light Image Enhancement](https://arxiv.org/pdf/2304.14610) INT
      2. [Efficient Halftoning via Deep Reinforcement Learning](https://arxiv.org/pdf/2304.12152)
   9.  Industrial Applications
   10. Navigation
       1.  [Can Agents Run Relay Race with Strangers? Generalization of RL to Out-of-Distribution Trajectories](https://arxiv.org/pdf/2304.13424)
       2.  [SocNavGym: A Reinforcement Learning Gym for Social Navigation](https://arxiv.org/pdf/2304.14102)
       3.  [When to Replan? An Adaptive Replanning Strategy for Autonomous Navigation using Deep Reinforcement Learning](https://arxiv.org/pdf/2304.12046)
       4.  [Adaptive Learning Path Navigation Based on Knowledge Tracing and Reinforcement Learning](https://arxiv.org/pdf/2305.04475)
       5.  [Dynamically Conservative Self-Driving Planner for Long-Tail Cases](https://arxiv.org/pdf/2305.07497)
       6.  [Efficient Reinforcement Learning for Autonomous Driving with Parameterized Skills and Priors](https://arxiv.org/pdf/2305.04412)
       7.  [Identify, Estimate and Bound the Uncertainty of Reinforcement Learning for Autonomous Driving](https://arxiv.org/pdf/2305.07487)
       8.  [Sense, Imagine, Act: Multimodal Perception Improves Model-Based Reinforcement Learning for Head-to-Head Autonomous Racing](https://arxiv.org/pdf/2305.04750)
       9.  [Sequence-Agnostic Multi-Object Navigation](https://arxiv.org/pdf/2305.06178)
   11. Networks
       1.  [A Federated Reinforcement Learning Framework for Link Activation in Multi-link Wi-Fi Networks](https://arxiv.org/pdf/2304.14720)
       2.  [Cooperative Hierarchical Deep Reinforcement Learning based Joint Sleep, Power, and RIS Control for Energy-Efficient HetNet](https://arxiv.org/pdf/2304.13226)
       3.  [Federated Deep Reinforcement Learning for THz-Beam Search with Limited CSI](https://arxiv.org/pdf/2304.13109)
       4.  [AI-based Radio and Computing Resource Allocation and Path Planning in NOMA NTNs: AoI Minimization under CSI Uncertainty](https://arxiv.org/pdf/2305.00780)
       5.  [Deep Reinforcement Learning Based Resource Allocation for Cloud Native Wireless Network](https://arxiv.org/pdf/2305.06249)
       6.  [Deep Reinforcement Learning for Interference Management in UAV-based 3D Networks: Potentials and Challenges](https://arxiv.org/pdf/2305.07069)
       7.  [Model-free Reinforcement Learning of Semantic Communication by Stochastic Policy Gradient](https://arxiv.org/pdf/2305.03571)
       8.  [PPO-ABR: Proximal Policy Optimization based Deep Reinforcement Learning for Adaptive BitRate streaming](https://arxiv.org/pdf/2305.08114)
   12. Robotics
       1.  [Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning](https://arxiv.org/pdf/2304.13653)
       2.  [Learning adaptive manipulation of objects with revolute joint: A case study on varied cabinet doors opening](https://arxiv.org/pdf/2304.14602)
       3.  [Active Semantic Localization with Graph Neural Embedding](https://arxiv.org/pdf/2305.06141)
       4.  [Deep RL at Scale: Sorting Waste in Office Buildings with a Fleet of Mobile Manipulators](https://arxiv.org/pdf/2305.03270)
       5.  [DexArt: Benchmarking Generalizable Dexterous Manipulation with Articulated Objects](https://arxiv.org/pdf/2305.05706)
       6.  [Enhancing Efficiency of Quadrupedal Locomotion over Challenging Terrains with Extensible Feet](https://arxiv.org/pdf/2305.01998)
       7.  [Learning Generalizable Pivoting Skills](https://arxiv.org/pdf/2305.02554)
       8.  [Learning Hybrid Actor-Critic Maps for 6D Non-Prehensile Manipulation](https://arxiv.org/pdf/2305.03942)
       9.  [More Than an Arm: Using a Manipulator as a Tail for Enhanced Stability in Legged Locomotion](https://arxiv.org/pdf/2305.01648) INT
   13. Scheduling
   14. Sound
   15. Quantum Computing
       1.  [Discovery of Optimal Quantum Error Correcting Codes via Reinforcement Learning](https://arxiv.org/pdf/2305.06378)
       2.  [Fast quantum gate design with deep reinforcement learning using real-time feedback on readout signals](https://arxiv.org/pdf/2305.01169)
   16. Others
2. __Reinforcement Learning Theory__
    1. Actor Critic
    2. Algorithms
       1. [Quantile-Based Deep Reinforcement Learning using Two-Timescale Policy Gradient Algorithms](https://arxiv.org/pdf/2305.07248)
    3. Attacks
       1. [NNSplitter: An Active Defense Solution to DNN Model via Automated Weight Obfuscation](https://arxiv.org/pdf/2305.00097)
       2. [Policy Resilience to Environment Poisoning Attacks on Reinforcement Learning](https://arxiv.org/pdf/2304.12151) INT
       3. [Topic-oriented Adversarial Attacks against Black-box Neural Ranking Models](https://arxiv.org/pdf/2304.14867) INT
       4. [IMAP: Intrinsically Motivated Adversarial Policy](https://arxiv.org/pdf/2305.02605) INT
       5. [Robust multi-agent coordination via evolutionary generation of auxiliary adversarial attackers](https://arxiv.org/pdf/2305.05909) 
       6. [Single Node Injection Label Specificity Attack on Graph Neural Networks via Reinforcement Learning](https://arxiv.org/pdf/2305.02901)
    4. Automated RL
    5. Bayes
    6. Causal RL
    7. Compositional RL
    8. Convex RL
    9. Contextual RL
    10. Continual learning
       1.  [Policy Gradient Algorithms Implicitly Optimize by Continuation](https://arxiv.org/pdf/2305.06851)
       2.  [Reducing the Cost of Cycle-Time Tuning for Real-World Policy Optimization](https://arxiv.org/pdf/2305.05760)
    11. Control Theory
        1.  [Deep Reinforcement Learning in Finite-Horizon to Explore the Most Probable Transition Pathway](https://arxiv.org/pdf/2304.12994)
        2.  [Reinforcement Learning with Partial Parametric Model Knowledge](https://arxiv.org/pdf/2304.13223)
        3.  [Behavior Contrastive Learning for Unsupervised Skill Discovery](https://arxiv.org/pdf/2305.04477)
    12. Correctional Learning
    13. Curriculum RL
        1.  [Proximal Curriculum for Reinforcement Learning Agents](https://arxiv.org/pdf/2304.12877)
    14. Data Augmentation
        1.  [Simple Noisy Environment Augmentation for Reinforcement Learning](https://arxiv.org/pdf/2305.02882)
    15. Deepmind
    16. Diffusion models
    17. Distributed RL
        1.  [Loss and Reward Weighing for increased learning in Distributed Reinforcement Learning](https://arxiv.org/pdf/2304.12778)
        2.  [One-Step Distributional Reinforcement Learning](https://arxiv.org/pdf/2304.14421)
    18. Episodic Control
    19. Evolutionary Learning
        1.  [Supplementing Gradient-Based Reinforcement Learning with Simple Evolutionary Ideas](https://arxiv.org/pdf/2305.07571)
    20. Exploration Methods
        1.  [FLEX: an Adaptive Exploration Algorithm for Nonlinear Systems](https://arxiv.org/pdf/2304.13426)
        2.  [An Autonomous Non-monolithic Agent with Multi-mode Exploration based on Options Framework](https://arxiv.org/pdf/2305.01322)
    21. Explainable/Interpretable Machine Learning
        1.  [A Closer Look at Reward Decomposition for High-Level Robotic Explanations](https://arxiv.org/pdf/2304.12958)
        2.  [N$\\text{A}^\\text{2}$Q: Neural Attention Additive Model for Interpretable Multi-Agent Q-Learning](https://arxiv.org/pdf/2304.13383)
        3.  [Explainable Reinforcement Learning via a Causal World Model](https://arxiv.org/pdf/2305.02749)
        4.  [Explaining RL Decisions with Trajectories](https://arxiv.org/pdf/2305.04073)(https://arxiv.org/pdf/2305.02749) INT
    22. Federated Learning
        1.  [Federated TD Learning over Finite-Rate Erasure Channels: Linear Speedup under Markovian Sampling](https://arxiv.org/pdf/2305.08104)
        2.  [Portfolio-Based Incentive Mechanism Design for Cross-Device Federated Learning](https://arxiv.org/pdf/2305.04081)
    23. Foundation models
    24. Generative Flow Networks
    25. Goal-oriented
        1.  [Goal-oriented inference of environment from redundant observations](https://arxiv.org/pdf/2305.04432)
    26. Graph RL
        1.  [Partially Observable Mean Field Multi-Agent Reinforcement Learning Based on Graph-Attention](https://arxiv.org/pdf/2304.12653)
        2.  [X-RLflow: Graph Reinforcement Learning for Neural Network Subgraphs Transformation](https://arxiv.org/pdf/2304.14698)
        3.  [Graph Neural Networks and 3-Dimensional Topology](https://arxiv.org/pdf/2305.05966)
        4.  [Learning to Code on Graphs for Topological Interference Management](https://arxiv.org/pdf/2305.07186)
        5.  [Towards Scalable Adaptive Learning with Graph Neural Networks and Reinforcement Learning](https://arxiv.org/pdf/2305.06398)
    27. Hierarchical RL
        1.  [Hierarchical State Abstraction Based on Structural Information Principles](https://arxiv.org/pdf/2304.12000)
    28. Instruction Learning
    29. Imitation / Inverse / Demonstration Reinforcement Learning
        1.  [A Coupled Flow Approach to Imitation Learning](https://arxiv.org/pdf/2305.00303)
        2.  [Inferring Preferences from Demonstrations in Multi-objective Reinforcement Learning: A Dynamic Weight-based Approach](https://arxiv.org/pdf/2304.14115)
        3.  [Towards Theoretical Understanding of Inverse Reinforcement Learning](https://arxiv.org/pdf/2304.12966)
        4.  [A proof of convergence of inverse reinforcement learning for multi-objective optimization](https://arxiv.org/pdf/2305.06137)
        5.  [Inverse Reinforcement Learning With Constraint Recovery](https://arxiv.org/pdf/2305.08130)
    30. Interpretability
    31. Irregular time
    32. Lifelong RL 
    33. Markov Decision Processes / Deep Theory
        1.  [Semi-Infinitely Constrained Markov Decision Processes and Efficient Reinforcement Learning](https://arxiv.org/pdf/2305.00254)
        2.  [An Option-Dependent Analysis of Regret Minimization Algorithms in Finite-Horizon Semi-Markov Decision Processes](https://arxiv.org/pdf/2305.06936)
        3.  [Model-agnostic Measure of Generalization Difficulty](https://arxiv.org/pdf/2305.01034) INT
        4.  [Reinforcement Learning with Delayed, Composite, and Partially Anonymous Reward](https://arxiv.org/pdf/2305.02527)
    34. Memory optimization
    35. Meta Learning
        1.  [Meta-Reinforcement Learning Based on Self-Supervised Task Representation Learning](https://arxiv.org/pdf/2305.00286)
    36. Multi-Agent RL
        1.  [SEA: A Spatially Explicit Architecture for Multi-Agent Reinforcement Learning](https://arxiv.org/pdf/2304.12532)
        2.  [An Algorithm For Adversary Aware Decentralized Networked MARL](https://arxiv.org/pdf/2305.05573) INT
        3.  [Boosting Value Decomposition via Unit-Wise Attentive State Representation for Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/pdf/2305.07182)
        4.  [Communication-Robust Multi-Agent Learning by Adaptable Auxiliary Multi-Agent Adversary Generation](https://arxiv.org/pdf/2305.05116)
        5.  [Cooperative Multi-Agent Reinforcement Learning: Asynchronous Communication and Linear Function Approximation](https://arxiv.org/pdf/2305.06446)
        6.  [Fast Teammate Adaptation in the Presence of Sudden Policy Change](https://arxiv.org/pdf/2305.05911)
        7.  [Information Design in Multi-Agent Reinforcement Learning](https://arxiv.org/pdf/2305.06807) INT
        8.  [Mixture of personality improved Spiking actor network for efficient multi-agent cooperation](https://arxiv.org/pdf/2305.05898)
        9.  [On the Complexity of Multi-Agent Decision Making: From Learning in Games to Partial Monitoring](https://arxiv.org/pdf/2305.00684)
        10. [SMAClite: A Lightweight Environment for Multi-Agent Reinforcement Learning](https://arxiv.org/pdf/2305.05566)
        11. [Stackelberg Decision Transformer for Asynchronous Action Coordination in Multi-Agent Systems](https://arxiv.org/pdf/2305.07856)
        12. [System Neural Diversity: Measuring Behavioral Heterogeneity in Multi-Agent Learning](https://arxiv.org/pdf/2305.02128)
    37. Multi-objective
    38. Multi-Task
        1.  [A Multi-Task Approach to Robust Deep Reinforcement Learning for Resource Allocation](https://arxiv.org/pdf/2304.12660)
    39. Model-based
    40. Model-free
        1.  [Sample Efficient Model-free Reinforcement Learning from LTL Specifications with Optimality Guarantees](https://arxiv.org/pdf/2305.01381)
    41. Needs-driven
    42. Offline RL
        1.  [Contrastive Energy Prediction for Exact Energy-Guided Diffusion Sampling in Offline Reinforcement Learning](https://arxiv.org/pdf/2304.12824)
        2.  [A Survey on Offline Model-Based Reinforcement Learning](https://arxiv.org/pdf/2305.03360) INT INT
        3.  [Federated Ensemble-Directed Offline Reinforcement Learning](https://arxiv.org/pdf/2305.03097)
    43. Off-policy RL
        1.  [Rethinking Population-assisted Off-policy Reinforcement Learning](https://arxiv.org/pdf/2305.02949)
    44. Optimization applications
    45. Partially Observable RL
    46. Planning
        1.  [Flexible Job Shop Scheduling via Dual Attention Network Based Reinforcement Learning](https://arxiv.org/pdf/2305.05119)
        2.  [Train a Real-world Local Path Planner in One Hour via Partially Decoupled Reinforcement Learning and Vectorized Diversity](https://arxiv.org/pdf/2305.04180)
        3.  [Truncating Trajectories in Monte Carlo Reinforcement Learning](https://arxiv.org/pdf/2305.04361)
    47. Policy/Value Optimization
        1.  [Adversarial Policy Optimization in Deep Reinforcement Learning](https://arxiv.org/pdf/2304.14533)
        2.  [Discovering Object-Centric Generalized Value Functions From Pixels](https://arxiv.org/pdf/2304.13892)
        3.  [Instance-Optimality in Interactive Decision Making: Toward a Non-Asymptotic Theory](https://arxiv.org/pdf/2304.12466)
        4.  [Proto-Value Networks: Scaling Representation Learning with Auxiliary Tasks](https://arxiv.org/pdf/2304.12567)
        5.  [Deep Q-Learning-based Distribution Network Reconfiguration for Reliability Improvement](https://arxiv.org/pdf/2305.01180)
        6.  [Delay-Adapted Policy Optimization and Improved Regret for Adversarial MDP with Delayed Bandit Feedback](https://arxiv.org/pdf/2305.07911)
        7.  [Latent Interactive A2C for Improved RL in Open Many-Agent Systems](https://arxiv.org/pdf/2305.05159)
        8.  [Map-based Experience Replay: A Memory-Efficient Solution to Catastrophic Forgetting in Reinforcement Learning](https://arxiv.org/pdf/2305.02054) INT
        9.  [Policy Gradient Methods in the Presence of Symmetries and State Abstractions](https://arxiv.org/pdf/2305.05666)
    48. Quality Diversity
    49. Quantum Computing
        1.  [Batch Quantum Reinforcement Learning](https://arxiv.org/pdf/2305.00905)
        2.  [Quantum Natural Policy Gradients: Towards Sample-Efficient Reinforcement Learning](https://arxiv.org/pdf/2304.13571)
    50. Regret Minimization
    51. Reinforcement Learning from Human Preferences/Feedback
    52. Representation Learning
    53. Risk-sensitive/safe/constrained RL
        1.  [DEFENDER: DTW-Based Episode Filtering Using Demonstrations for Enhancing RL Safety](https://arxiv.org/pdf/2305.04727)
        2.  [Learning Failure Prevention Skills for Safe Robot Manipulation](https://arxiv.org/pdf/2305.02807)
        3.  [Maximum Causal Entropy Inverse Constrained Reinforcement Learning](https://arxiv.org/pdf/2305.02857)
        4.  [More for Less: Safe Policy Improvement With Stronger Performance Guarantees](https://arxiv.org/pdf/2305.07958) INT
        5.  [On the Optimality, Stability, and Feasibility of Control Barrier Functions: An Adaptive Learning-Based Approach](https://arxiv.org/pdf/2305.03608)
        6.  [Safe Deep RL for Intraoperative Planning of Pedicle Screw Placement](https://arxiv.org/pdf/2305.05354)
        7.  [Towards Theoretical Understanding of Data-Driven Policy Refinement](https://arxiv.org/pdf/2305.06796)
    54. Robust RL
        1.  [CROP: Towards Distributional-Shift Robust Reinforcement Learning using Compact Reshaped Observation Processing](https://arxiv.org/pdf/2304.13616)
        2.  [On Practical Robust Reinforcement Learning: Practical Uncertainty Set and Double-Agent Algorithm](https://arxiv.org/pdf/2305.06657)
    55. Reviews
    56. Reward Optimization
    57. Sample-efficiency
        1.  [Provable benefits of general coverage conditions in efficient online RL with function approximation](https://arxiv.org/pdf/2304.12886)
    58. Scheduling
    59. Sim-to-real
        1.  [Roll-Drop: accounting for observation noise with a single parameter](https://arxiv.org/pdf/2304.13150)
    60. Task-driven RL
        1.  [Composite Motion Learning with Task Control](https://arxiv.org/pdf/2305.03286)
    61. Teacher-Student Framework
        1.  [Knowledge Transfer from Teachers to Learners in Growing-Batch Reinforcement Learning](https://arxiv.org/pdf/2305.03870)
    62. Temporal Difference Learning
    63. Time-Series Learning
    64. Transformers
    65. Others
        1.  [Fundamental Tradeoffs in Learning with Prior Information](https://arxiv.org/pdf/2304.13479)
3. __Recommender Systems__
   1. [Automated Data Denoising for Recommendation](https://arxiv.org/pdf/2305.07070)
   2. [Sim2Rec: A Simulator-based Decision-making Approach to Optimize Real-World Long-term User Engagement in Sequential Recommender Systems](https://arxiv.org/pdf/2305.04832)
   3. [Towards Hierarchical Policy Learning for Conversational Recommendation with Hypergraph-based Reinforcement Learning](https://arxiv.org/pdf/2305.02575)
4. __Legal Applications__
5. __Education__
   1. [Towards Applying Powerful Large AI Models in Classroom Teaching: Opportunities, Challenges and Prospects](https://arxiv.org/pdf/2305.03433) INT
6. __Financial Applications__
   1. [Dynamic Datasets and Market Environments for Financial Reinforcement Learning](https://arxiv.org/pdf/2304.13174)
   2. [Fulfilling Formal Specifications ASAP by Model-free Reinforcement Learning](https://arxiv.org/pdf/2304.12508)
   3. [Improving Real-Time Bidding in Online Advertising Using Markov Decision Processes and Machine Learning Techniques](https://arxiv.org/pdf/2305.04889)
   4. [Validation of massively-parallel adaptive testing using dynamic control matching](https://arxiv.org/pdf/2305.01334)
   5. [evaluating bert and parsbert for analyzing persian advertisement data](https://arxiv.org/pdf/2305.02426)
7. __Human-agent interaction__
   1. [Human Machine Co-adaption Interface via Cooperation Markov Decision Process System](https://arxiv.org/pdf/2305.02058) INT INT
8. __Games and Game Theory__
   1. [Centralized control for multi-agent RL in a complex Real-Time-Strategy game](https://arxiv.org/pdf/2304.13004)
   2. [Stubborn: An Environment for Evaluating Stubbornness between Agents with Aligned Incentives](https://arxiv.org/pdf/2304.12280)
   3. [Cooperative Driving of Connected Autonomous Vehicles in Heterogeneous Mixed Traffic: A Game Theoretic Approach](https://arxiv.org/pdf/2305.03563)
   4. [Learnable Behavior Control: Breaking Atari Human World Records via Sample-Efficient Behavior Selection](https://arxiv.org/pdf/2305.05239)
   5. [Stackelberg Games for Learning Emergent Behaviors During Competitive Autocurricula](https://arxiv.org/pdf/2305.03735)
9.  __Biology__
    1.  [Biophysical Cybernetics of Directed Evolution and Eco-evolutionary Dynamics](https://arxiv.org/pdf/2305.03340)
10. __Physics__
    1.  [An efficient neural optimizer for resonant nanostructures: demonstration of highly-saturated red silicon structural color](https://arxiv.org/pdf/2304.13516)
    2.  [Exploring the flavor structure of quarks and leptons with reinforcement learning](https://arxiv.org/pdf/2304.14176)
    3.  [Parallel bootstrap-based on-policy deep reinforcement learning for continuous flow control applications](https://arxiv.org/pdf/2304.12330)
    4.  [Gym-preCICE: Reinforcement Learning Environments for Active Flow Control](https://arxiv.org/pdf/2305.02033)
    5.  [Large-Eddy Simulation of Flow over Boeing Gaussian Bump Using Multi-Agent Reinforcement Learning Wall Model](https://arxiv.org/pdf/2305.02540)
    6.  [Reducing the Drag of a Bluff Body by Deep Reinforcement Learning](https://arxiv.org/pdf/2305.03647)
11. __Psychology__:
    1.  [Bayesian Reinforcement Learning with Limited Cognitive Load](https://arxiv.org/pdf/2305.03263) INT INT
    2.  [Heterogeneous Social Value Orientation Leads to Meaningful Diversity in Sequential Social Dilemmas](https://arxiv.org/pdf/2305.00768) INT INT
12. __Philosophy and Ethics__:
    1.  [Reinforcement Learning with Knowledge Representation and Reasoning: A Brief Survey](https://arxiv.org/pdf/2304.12090) INT INT
13. __Healthcare Applications__
    1.  [Active Reinforcement Learning for Personalized Stress Monitoring in Everyday Settings](https://arxiv.org/pdf/2305.00111) 
    2.  [A optimization framework for herbal prescription planning based on deep reinforcement learning](https://arxiv.org/pdf/2304.12828) (Controversial, Traditional Chinese Medicine)
    3.  [An Adaptive Behaviour-Based Strategy for SARs interacting with Older Adults with MCI during a Serious Game Scenario](https://arxiv.org/pdf/2305.01492) INT
    4.  [Cooperating Graph Neural Networks with Deep Reinforcement Learning for Vaccine Prioritization](https://arxiv.org/pdf/2305.05163)
    5.  [Extracting Diagnosis Pathways from Electronic Health Records Using Deep Reinforcement Learning](https://arxiv.org/pdf/2305.06295)
    6.  [Leveraging Factored Action Spaces for Efficient Offline Reinforcement Learning in Healthcare](https://arxiv.org/pdf/2305.01738)
14. __Natural Language Processing__
    1.  [A Minimal Approach for Natural Language Action Space in Text-based Games](https://arxiv.org/pdf/2305.04082) INT INT
    2.  [A framework for the emergence and analysis of language in social learning agents](https://arxiv.org/pdf/2305.02632) INT INT
    3.  [An Asynchronous Updating Reinforcement Learning Framework for Task-oriented Dialog System](https://arxiv.org/pdf/2305.02718)
    4.  [ChatGPT-steered Editing Instructor for Customization of Abstractive Summarization](https://arxiv.org/pdf/2305.02483)
    5.  [Fine-tuning Language Models with Generative Adversarial Feedback](https://arxiv.org/pdf/2305.06176) INT
    6.  [Gaussian Prior Reinforcement Learning for Nested Named Entity Recognition](https://arxiv.org/pdf/2305.07266)
    7.  [Knowledge-enhanced Agents for Interactive Text Games](https://arxiv.org/pdf/2305.05091) INT
    8.  [Large Language Models Can Be Used To Effectively Scale Spear Phishing Campaigns](https://arxiv.org/pdf/2305.06972) INT
    9.  [Mitigating Approximate Memorization in Language Models via Dissimilarity Learned Policy](https://arxiv.org/pdf/2305.01550)
    10. [No More Manual Tests? Evaluating and Improving ChatGPT for Unit Test Generation](https://arxiv.org/pdf/2305.04207)
    11. [Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision](https://arxiv.org/pdf/2305.03047) INT INT
    12. [Reinforcement Learning for Topic Models](https://arxiv.org/pdf/2305.04843)
    13. [Replicating Complex Dialogue Policy of Humans via Offline Imitation Learning with Supervised Regularization](https://arxiv.org/pdf/2305.03987)
    14. [Rescue Conversations from Dead-ends: Efficient Exploration for Task-oriented Dialogue Policy Optimization](https://arxiv.org/pdf/2305.03262) INT
    15. [Task-Optimized Adapters for an End-to-End Task-Oriented Dialogue System](https://arxiv.org/pdf/2305.02468)
15. __Mathematics__
16. __Sociology__
    1.  [Learning Optimal \"Pigovian Tax\" in Sequential Social Dilemmas](https://arxiv.org/pdf/2305.06227)
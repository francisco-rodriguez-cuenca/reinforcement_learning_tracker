# Notes on RL 20

__89__

Using arxiv scraper

## New papers

1. __Engineering Applications__
   1. Agriculture
   2. Computing and Software Engineering
      1. [BitE : Accelerating Learned Query Optimization in a Mixed-Workload Environment](https://arxiv.org/pdf/2306.00845)
   3. Cyber Security 
   4. Cyber Operations (CyOps)
   5. Energy
      1. [Centralised rehearsal of decentralised cooperation: Multi-agent reinforcement learning for the scalable coordination of residential energy flexibility](https://arxiv.org/pdf/2305.18875)
   6. Environment
   7. Image & Video
      1. [Controllable Motion Diffusion Model](https://arxiv.org/pdf/2306.00416)
   8. Industrial Applications
      1. [A Modular Test Bed for Reinforcement Learning Incorporation into Industrial Applications](https://arxiv.org/pdf/2306.01440)
      2. [An Architecture for Deploying Reinforcement Learning in Industrial Environments](https://arxiv.org/pdf/2306.01420)
   9.  Navigation
       1.  [Adaptive and Explainable Deployment of Navigation Skills via Hierarchical Deep Reinforcement Learning](https://arxiv.org/pdf/2305.19746) INT
       2.  [Efficient Learning of Urban Driving Policies Using Bird's-Eye-View State Representations](https://arxiv.org/pdf/2305.19904)
       3.  [Investigating Navigation Strategies in the Morris Water Maze through Deep Reinforcement Learning](https://arxiv.org/pdf/2306.01066)
       4.  [RLAD: Reinforcement Learning from Pixels for Autonomous Driving in Urban Environments](https://arxiv.org/pdf/2305.18510)
   10. Networks
       1.  [Average AoI Minimization for Energy Harvesting Relay-aided Status Update Network Using Deep Reinforcement Learning](https://arxiv.org/pdf/2306.01251)
       2.  [DHRL-FNMR: An Intelligent Multicast Routing Approach Based on Deep Hierarchical Reinforcement Learning in SDN](https://arxiv.org/pdf/2305.19077)
       3.  [Training Terahertz Wireless Systems to Battle I/Q Imbalance](https://arxiv.org/pdf/2306.01611)
   11. Traffic & Flow
       1.  [Perimeter Control Using Deep Reinforcement Learning: A Model-free Approach towards Homogeneous Flow Rate Optimization](https://arxiv.org/pdf/2305.19291)
   12. Robotics
       1.  [Active Reinforcement Learning under Limited Visual Observability](https://arxiv.org/pdf/2306.00975)
       2.  [Granular Gym: High Performance Simulation for Robotic Tasks with Granular Materials](https://arxiv.org/pdf/2306.01369)
       3.  [LIV: Language-Image Representations and Rewards for Robotic Control](https://arxiv.org/pdf/2306.00958)
       4.  [Multi-Robot Path Planning Combining Heuristics and Multi-Agent Reinforcement Learning](https://arxiv.org/pdf/2306.01270)
   13. Scheduling
   14. Sound
   15. Quantum Computing
   16. UAV's
       1.  [A Hybrid Framework of Reinforcement Learning and Convex Optimization for UAV-Based Autonomous Metaverse Data Collection](https://arxiv.org/pdf/2305.18481)
   17. Others
       1.  [Action valuation of on- and off-ball soccer players based on multi-agent deep reinforcement learning](https://arxiv.org/pdf/2305.17886)
       2.  [Simulation and Retargeting of Complex Multi-Character Interactions](https://arxiv.org/pdf/2305.20041)
2.  __Reinforcement Learning Theory__
    1. Actor Critic
       1. [ReLU to the Rescue: Improve Your On-Policy Actor-Critic with Positive Advantages](https://arxiv.org/pdf/2306.01460)
    2. Algorithms
       1. [Deep Q-Learning versus Proximal Policy Optimization: Performance Comparison in a Material Sorting Task](https://arxiv.org/pdf/2306.01451) INT
       2. [VA-learning as a more efficient alternative to Q-learning](https://arxiv.org/pdf/2305.18161)
    3. Attacks
    4. Automated RL
    5. Bayes
    6. Causal RL
    7. Compositional RL
    8. Computational Efficiency
       1. [Handling Large Discrete Action Spaces via Dynamic Neighborhood Construction](https://arxiv.org/pdf/2305.19891)
    9.  Convex RL
    10. Contextual RL
    11. Continual learning
        1.  [Policy Optimization for Continuous Reinforcement Learning](https://arxiv.org/pdf/2305.18901)
    12. Control Theory
        1.  [Improving the performance of Learned Controllers in Behavior Trees using Value Function Estimates at Switching Boundaries](https://arxiv.org/pdf/2305.18903)
    13. Cooperators
    14. Correctional Learning
    15. Curriculum RL
    16. Data Augmentation
    17. Diffussion Models
    18. Deepmind
    19. Deep Reinforcement Learning
    20. Diffusion models
    21. Distributed RL
    22. Empirical Study of RL
        1.  [Hyperparameters in Reinforcement Learning and How To Tune Them](https://arxiv.org/pdf/2306.01324) INT INT
        2.  [Replicability in Reinforcement Learning](https://arxiv.org/pdf/2305.19562)
    23. Episodic Control
    24. Evolutionary Learning
    25. Exploration Methods
        1.  [Accelerating Reinforcement Learning with Value-Conditional State Entropy Exploration](https://arxiv.org/pdf/2305.19476)
        2.  [Latent Exploration for Reinforcement Learning](https://arxiv.org/pdf/2305.20065)
        3.  [One Objective to Rule Them All: A Maximization Objective Fusing Estimation and Planning for Exploration](https://arxiv.org/pdf/2305.18258)
        4.  [Provable and Practical: Efficient Exploration in Reinforcement Learning via Langevin Monte Carlo](https://arxiv.org/pdf/2305.18246)
        5.  [Symmetric Exploration in Combinatorial Optimization is Free!](https://arxiv.org/pdf/2306.01276) INT
    26. Explainable/Interpretable Machine Learning
        1.  [Interpretable and Explainable Logical Policies via Neurally Guided Symbolic Abstraction](https://arxiv.org/pdf/2306.01439)
    27. Feature Engineering
    28. Federated Learning
        1.  [Federated Multi-Sequence Stochastic Approximation with Local Hypergradient Estimation](https://arxiv.org/pdf/2306.01648)
    29. Foundation models
    30. Generalization
    31. Generative Flow Networks
    32. Goals
    33. Graph RL
        1.  [CLIPGraphs: Multimodal Graph Networks to Infer Object-Room Affinities](https://arxiv.org/pdf/2306.01540)
        2.  [Subequivariant Graph Reinforcement Learning in 3D Environments](https://arxiv.org/pdf/2305.18951)
    34. Hierarchical RL
        1.  [Hierarchical Reinforcement Learning for Modeling User Novelty-Seeking Intent in Recommender Systems](https://arxiv.org/pdf/2306.01476)
        2.  [IQL-TD-MPC: Implicit Q-Learning for Hierarchical Model Predictive Control](https://arxiv.org/pdf/2306.00867)
    35. Hybrid RL
    36. Instruction Learning
    37. Imitation / Inverse / Demonstration Reinforcement Learning
        1.  [Identifiability and Generalizability in Constrained Inverse Reinforcement Learning](https://arxiv.org/pdf/2306.00629) INT
        2.  [NetHack is Hard to Hack](https://arxiv.org/pdf/2305.19240) INT
        3.  [PAGAR: Imitation Learning with Protagonist Antagonist Guided Adversarial Reward](https://arxiv.org/pdf/2306.01731) INT INT
    38. Interpretability
    39. Irregular time
    40. Lifelong RL 
    41. Markov Decision Processes / Deep Theory
        1.  [Achieving Fairness in Multi-Agent Markov Decision Processes Using Reinforcement Learning](https://arxiv.org/pdf/2306.00324)
        2.  [Differentially Private Episodic Reinforcement Learning with Heavy-tailed Rewards](https://arxiv.org/pdf/2306.01121)
        3.  [Non-stationary Reinforcement Learning under General Function Approximation](https://arxiv.org/pdf/2306.00861)
    42. Memory optimization
    43. Meta Learning
        1.  [Offline Meta Reinforcement Learning with In-Distribution Online Adaptation](https://arxiv.org/pdf/2305.19529) INT
    44. Model-based
        1.  [Pre-training Contextualized World Models with In-the-wild Videos for Reinforcement Learning](https://arxiv.org/pdf/2305.18499)
    45. Model-free
    46. Modular RL
        1.  [Augmented Modular Reinforcement Learning based on Heterogeneous Knowledge](https://arxiv.org/pdf/2306.01158)
    47. Multi-Agent RL
        1.  [AccMER: Accelerating Multi-Agent Experience Replay with Cache Locality-aware Prioritization](https://arxiv.org/pdf/2306.00187)
    48. Multi-objective
    49. Multi-Task RL
        1.  [Diffusion Model is an Effective Planner and Data Synthesizer for Multi-Task Reinforcement Learning](https://arxiv.org/pdf/2305.18459) INT
        2.  [Independent Component Alignment for Multi-Task Learning](https://arxiv.org/pdf/2305.19000)
    50. Needs-driven
    51. Neural Networks
    52. Offline RL
        1.  [A Convex Relaxation Approach to Bayesian Regret Minimization in Offline Bandits](https://arxiv.org/pdf/2306.01237)
        2.  [Delphic Offline Reinforcement Learning under Nonidentifiable Hidden Confounding](https://arxiv.org/pdf/2306.01157)
        3.  [Efficient Diffusion Policies for Offline Reinforcement Learning](https://arxiv.org/pdf/2305.20081)
        4.  [Improving and Benchmarking Offline Reinforcement Learning Algorithms](https://arxiv.org/pdf/2306.00972)
        5.  [MetaDiffuser: Diffusion Model as Conditional Planner for Offline Meta-RL](https://arxiv.org/pdf/2305.19923)
    53. Off-policy RL
    54. Online RL
    55. Optimization
    56. Partially Observable RL
    57. Planning
    58. Policy/Value Optimization
    59. Quality Diverse RL
        1.  [Generating Behaviorally Diverse Policies with Latent Diffusion Models](https://arxiv.org/pdf/2305.18738)
    60. Quantum Computing
        1.  [Quafu-RL: The Cloud Quantum Computers based Quantum Reinforcement Learning](https://arxiv.org/pdf/2305.17966)
    61. Regret Minimization
    62. Reinforcement Learning from Human Preferences/Feedback
        1.  [Fine-Grained Human Feedback Gives Better Rewards for Language Model Training](https://arxiv.org/pdf/2306.01693)
        2.  [How to Query Human Feedback Efficiently in RL?](https://arxiv.org/pdf/2305.18505)
    63. Representation Learning
        1.  [Representation-Driven Reinforcement Learning](https://arxiv.org/pdf/2305.19922)
        2.  [Towards a Better Understanding of Representation Dynamics under TD-learning](https://arxiv.org/pdf/2305.18491)
    64. Reviews
    65. Reward Optimization
    66. Reward-conditioned RL
    67. Risk-sensitive/safe/constrained RL
        1.  [Provably Efficient Generalized Lagrangian Policy Optimization for Safe Multi-Agent Reinforcement Learning](https://arxiv.org/pdf/2306.00212)
        2.  [ROSARL: Reward-Only Safe Reinforcement Learning](https://arxiv.org/pdf/2306.00035)
        3.  [Safe Offline Reinforcement Learning with Real-Time Budget Constraints](https://arxiv.org/pdf/2306.00603)
    68. Robust RL
        1.  [Efficient RL with Impaired Observability: Learning to Act with Delayed and Missing State Observations](https://arxiv.org/pdf/2306.01243)
        2.  [Learning for Edge-Weighted Online Bipartite Matching with Robustness Guarantees](https://arxiv.org/pdf/2306.00172)
        3.  [Solving Robust MDPs through No-Regret Dynamics](https://arxiv.org/pdf/2305.19035)
    69. Sample-efficiency
    70. Scheduling
    71. Sim-to-real
        1.  [Privileged Knowledge Distillation for Sim-to-Real Policy Generalization](https://arxiv.org/pdf/2305.18464)
    72. Task RL
    73. Teacher-Student Framework
    74. Temporal Difference Learning
    75. Text-to-image
    76. Time-Series Learning
    77. Theory of Information
    78. Transfer RL
    79. Transformers
        1.  [Blockwise Parallel Transformer for Long Context Large Models](https://arxiv.org/pdf/2305.19370)
    80. Vision-Language Models
        1.  [Test-Time Adaptation with CLIP Reward for Zero-Shot Generalization in Vision-Language Models](https://arxiv.org/pdf/2305.18010)
    81. Visual RL
        1.  [Normalization Enhances Generalization in Visual Reinforcement Learning](https://arxiv.org/pdf/2306.00656)
    82. Others
        1.  [TorchRL: A data-driven decision-making library for PyTorch](https://arxiv.org/pdf/2306.00577)
3. __Recommender Systems__
   1. [Robust Reinforcement Learning Objectives for Sequential Recommender Systems](https://arxiv.org/pdf/2305.18820)
4. __Legal Applications__
5. __Education__
6. __Financial Applications__
7. __Human-agent interaction__
8. __Games and Game Theory__
   1. [Score-Based Equilibrium Learning in Multi-Player Finite Games with Imperfect Information](https://arxiv.org/pdf/2306.00350)
   2. [What model does MuZero learn?](https://arxiv.org/pdf/2306.00840)
9.  __Biology__
10. __Physics__
11. __Chemistry__
12. __Psychology__
13. __Philosophy and Ethics__
    1.  [Doing the right thing for the right reason: Evaluating artificial moral cognition by probing cost insensitivity](https://arxiv.org/pdf/2305.18269) INT
    2.  [Intent-aligned AI systems deplete human agency: the need for agency foundations research in AI safety](https://arxiv.org/pdf/2305.19223) INT
14. __Healthcare Applications__
    1.  [Deep Reinforcement Learning Framework for Thoracic Diseases Classification via Prior Knowledge Guidance](https://arxiv.org/pdf/2306.01232)
    2.  [FRAMM: Fair Ranking with Missing Modalities for Clinical Trial Site Selection](https://arxiv.org/pdf/2305.19407)
    3.  [Multi-environment lifelong deep reinforcement learning for medical imaging](https://arxiv.org/pdf/2306.00188)
15. __Natural Language Processing__
    1.  [Adapting Pre-trained Language Models to Vision-Language Tasks via Dynamic Visual Prompting](https://arxiv.org/pdf/2306.00409)
    2.  [Adversarial learning of neural user simulators for dialogue policy optimisation](https://arxiv.org/pdf/2306.00858)
    3.  [Chatting Makes Perfect -- Chat-based Image Retrieval](https://arxiv.org/pdf/2305.20062)
    4.  [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/pdf/2305.18290) INT
    5.  [Factually Consistent Summarization via Reinforcement Learning with Textual Entailment Feedback](https://arxiv.org/pdf/2306.00186) INT
    6.  [Thought Cloning: Learning to Think while Acting by Imitating Human Thinking](https://arxiv.org/pdf/2306.00323)
16. __Mathematics__
17. __Sociology__
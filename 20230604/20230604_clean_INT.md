# Notes on RL 20

1. [A Modular Test Bed for Reinforcement Learning Incorporationo Industrial Applications](https://arxiv.org/pdf/2306.01440)
2.  [Adaptive and Explainable Deployment of Navigation Skills via Hierarchical Deep Reinforcement Learning](https://arxiv.org/pdf/2305.19746)
3.  [DHRL-FNMR: Anelligent Multicast Routing Approach Based on Deep Hierarchical Reinforcement Learning in SDN](https://arxiv.org/pdf/2305.19077)
4.  [Simulation and Retargeting of Complex Multi-Charactereractions](https://arxiv.org/pdf/2305.20041)
5. [Deep Q-Learning versus Proximal Policy Optimization: Performance Comparison in a Material Sorting Task](https://arxiv.org/pdf/2306.01451)
6.  [Hyperparameters in Reinforcement Learning and How To Tune Them](https://arxiv.org/pdf/2306.01324)
7.  [Symmetric Exploration in Combinatorial Optimization is Free!](https://arxiv.org/pdf/2306.01276)
8.  [Interpretable and Explainable Logical Policies via Neurally Guided Symbolic Abstraction](https://arxiv.org/pdf/2306.01439)
9.  [Hierarchical Reinforcement Learning for Modeling User Novelty-Seekingent in Recommender Systems](https://arxiv.org/pdf/2306.01476)
10. [Identifiability and Generalizability in Constrained Inverse Reinforcement Learning](https://arxiv.org/pdf/2306.00629)
11. [NetHack is Hard to Hack](https://arxiv.org/pdf/2305.19240)
12. [PAGAR: Imitation Learning with Protagonist Antagonist Guided Adversarial Reward](https://arxiv.org/pdf/2306.01731)
13. [Offline Meta Reinforcement Learning with In-Distribution Online Adaptation](https://arxiv.org/pdf/2305.19529)
14. [Diffusion Model is an Effective Planner and Data Synthesizer for Multi-Task Reinforcement Learning](https://arxiv.org/pdf/2305.18459)
15. [Safe Offline Reinforcement Learning with Real-Time Budget Constraints](https://arxiv.org/pdf/2306.00603)
16. [Doing the right thing for the right reason: Evaluating artificial moral cognition by probing cost insensitivity](https://arxiv.org/pdf/2305.18269)
17. [Intent-aligned AI systems deplete human agency: the need for agency foundations research in AI safety](https://arxiv.org/pdf/2305.19223)
18. [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/pdf/2305.18290)
19. [Factually Consistent Summarization via Reinforcement Learning with Textual Entailment Feedback](https://arxiv.org/pdf/2306.00186)
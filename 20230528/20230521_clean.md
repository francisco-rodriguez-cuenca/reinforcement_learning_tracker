# Notes on RL 19

__132__

Using arxiv scraper

## New papers

1. __Engineering Applications__
   1. Energy
      1. [Bayesian Reinforcement Learning for Automatic Voltage Control under Cyber-Induced Uncertainty](https://arxiv.org/pdf/2305.16469)
   2. Image & Video
      1. [Collaborative Multi-Agent Video Fast-Forwarding](https://arxiv.org/pdf/2305.17569)
   3.  Industrial Applications
       1.  [A Mini Review on the utilization of Reinforcement Learning with OPC UA](https://arxiv.org/pdf/2305.15113)
       2.  [INVICTUS: Optimizing Boolean Logic Circuit Synthesis via Synergistic Learning and Search](https://arxiv.org/pdf/2305.13164)
       3.  [IndustReal: Transferring Contact-Rich Assembly Tasks from Simulation to Reality](https://arxiv.org/pdf/2305.17110)
   4.  Navigation
       1.  [Deep Reinforcement Learning-based Multi-objective Path Planning on the Off-road Terrain Environment for Ground Vehicles](https://arxiv.org/pdf/2305.13783)
       2.  [How To Not Train Your Dragon: Training-free Embodied Object Goal Navigation with Semantic Frontiers](https://arxiv.org/pdf/2305.16925)
       3.  [KARNet: Kalman Filter Augmented Recurrent Neural Network for Learning World Models in Autonomous Driving Tasks](https://arxiv.org/pdf/2305.14644)
       4.  [Spatio-Temporal Transformer-Based Reinforcement Learning for Robot Crowd Navigation](https://arxiv.org/pdf/2305.16612)
   5.  Networks
       1.  [Distributed Online Rollout for Multivehicle Routing in Unmapped Environments](https://arxiv.org/pdf/2305.15596)
       2.  [Road Planning for Slums via Deep Reinforcement Learning](https://arxiv.org/pdf/2305.13060)
       3.  [Sample Efficient Reinforcement Learning in Mixed Systems through Augmented Samples and Its Applications to Queueing Networks](https://arxiv.org/pdf/2305.16483)
       4.  [Scaling Serverless Functions in Edge Networks: A Reinforcement Learning Approach](https://arxiv.org/pdf/2305.13130)
       5.  [Semantic-aware Transmission Scheduling: a Monotonicity-driven Deep Reinforcement Learning Approach](https://arxiv.org/pdf/2305.13706)
       6.  [XRoute Environment: A Novel Reinforcement Learning Environment for Routing](https://arxiv.org/pdf/2305.13823)รง
   6.  Robotics
       1.  [Adaptive PD Control using Deep Reinforcement Learning for Local-Remote Teleoperation with Stochastic Time Delays](https://arxiv.org/pdf/2305.16979)
       2.  [Aerial Gym -- Isaac Gym Simulator for Aerial Robots](https://arxiv.org/pdf/2305.16510)
       3.  [Barkour: Benchmarking Animal-level Agility with Quadruped Robots](https://arxiv.org/pdf/2305.14654)
       4.  [Communication-Efficient Reinforcement Learning in Swarm Robotic Networks for Maze Exploration](https://arxiv.org/pdf/2305.17087)
       5.  [Constrained Reinforcement Learning for Dynamic Material Handling](https://arxiv.org/pdf/2305.13824)
       6.  [Formal Modelling for Multi-Robot Systems Under Uncertainty](https://arxiv.org/pdf/2305.17018)
       7.  [FurnitureBench: Reproducible Real-World Benchmark for Long-Horizon Complex Manipulation](https://arxiv.org/pdf/2305.12821)
       8.  [Learning from demonstrations: An intuitive VR environment for imitation learning of construction robots](https://arxiv.org/pdf/2305.14584)
       9.  [MARC: A multi-agent robots control framework for enhancing reinforcement learning in construction tasks](https://arxiv.org/pdf/2305.14586)
       10. [M-EMBER: Tackling Long-Horizon Mobile Manipulation via Factorized Domain Transfer](https://arxiv.org/pdf/2305.13567)
       11. [Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning](https://arxiv.org/pdf/2305.13795)
2.  __Reinforcement Learning Theory__
    1. Actor Critic
       1. [Decision-Aware Actor-Critic with Function Approximation and Theoretical Guarantees](https://arxiv.org/pdf/2305.15249)
       2. [Scalable Primal-Dual Actor-Critic Method for Safe Multi-Agent RL with General Utilities](https://arxiv.org/pdf/2305.17568)
    2. Attacks
       1. [Rethinking Adversarial Policies: A Generalized Attack Formulation and Provable Defense in Multi-Agent RL](https://arxiv.org/pdf/2305.17342)
    3.  Control Theory
        1.  [Reinforcement Learning based optimal control with a probabilistic risk constraint](https://arxiv.org/pdf/2305.15755) 
        2.  [Solving Stabilize-Avoid Optimal Control via Epigraph Form and Deep Reinforcement Learning](https://arxiv.org/pdf/2305.14154)
    4.  Curriculum RL
        1.  [Reward-Machine-Guided, Self-Paced Reinforcement Learning](https://arxiv.org/pdf/2305.16505)
    5.  Diffussion Models
        1.  [Training Diffusion Models with Reinforcement Learning](https://arxiv.org/pdf/2305.13301)
    6.  Deep Reinforcement Learning
        1.  [RLBoost: Boosting Supervised Models using Deep Reinforcement Learning](https://arxiv.org/pdf/2305.14115)
    7.  Distributed RL
        1.  [The Benefits of Being Distributional: Small-Loss Bounds for Reinforcement Learning](https://arxiv.org/pdf/2305.15703)
        2.  [The Curious Price of Distributional Robustness in Reinforcement Learning with a Generative Model](https://arxiv.org/pdf/2305.16589)
    8.  Empirical Study of RL
        1.  [Replicable Reinforcement Learning](https://arxiv.org/pdf/2305.15284)
        2.  [Testing of Deep Reinforcement Learning Agents with Surrogate Models](https://arxiv.org/pdf/2305.12751)
    9.  Evolutionary Learning
        1.  [Learning to Act through Evolution of Neural Diversity in Random Neural Networks](https://arxiv.org/pdf/2305.15945)
    10. Exploration Methods
        1.  [L-SA: Learning Under-Explored Targets in Multi-Target Reinforcement Learning](https://arxiv.org/pdf/2305.13741)
        2.  [Successor-Predecessor Intrinsic Exploration](https://arxiv.org/pdf/2305.15277)
    11. Explainable/Interpretable Machine Learning
        1.  [Counterfactual Explainer Framework for Deep Reinforcement Learning Models Using Policy Distillation](https://arxiv.org/pdf/2305.16532)
    12. Feature Engineering
        1.  [Conditional Mutual Information for Disentangled Representations in Reinforcement Learning](https://arxiv.org/pdf/2305.14133)
        2.  [Self-Supervised Reinforcement Learning that Transfers using Random Features](https://arxiv.org/pdf/2305.17250)
    13. Generalization
        1.  [Cross-Domain Policy Adaptation via Value-Guided Data Filtering](https://arxiv.org/pdf/2305.17625)
        2.  [NASimEmu: Network Attack Simulator & Emulator for Training Agents Generalizing to Novel Scenarios](https://arxiv.org/pdf/2305.17246)
    14. Imitation / Inverse / Demonstration Reinforcement Learning
        1.  [Adaptive action supervision in reinforcement learning from real-world multi-agent demonstrations](https://arxiv.org/pdf/2305.13030)
        2.  [Coherent Soft Imitation Learning](https://arxiv.org/pdf/2305.16498)
        3.  "[GAME-UP: Game-Aware Mode Enumeration and Understanding for Trajectory Prediction](https://arxiv.org/pdf/2305.17600)
        4.  [Learning Safety Constraints from Demonstrations with Unknown Rewards](https://arxiv.org/pdf/2305.16147)
    15. Markov Decision Processes / Deep Theory
        1.  [Accelerating Value Iteration with Anchoring](https://arxiv.org/pdf/2305.16569)
        2.  [Distributional Reinforcement Learning with Dual Expectile-Quantile Regression](https://arxiv.org/pdf/2305.16877)
        3.  [Koopman Kernel Regression](https://arxiv.org/pdf/2305.16215)
        4.  [Markov Decision Process with an External Temporal Process](https://arxiv.org/pdf/2305.16056)
        5.  [Policy Synthesis and Reinforcement Learning for Discounted LTL](https://arxiv.org/pdf/2305.17115)
        6.  [Regret-Optimal Model-Free Reinforcement Learning for Discounted MDPs with Short Burn-In Time](https://arxiv.org/pdf/2305.15546)
        7.  [Regularization and Variance-Weighted Regression Achieves Minimax Optimality in Linear MDPs: Theory and Practice](https://arxiv.org/pdf/2305.13185)
        8.  [Reviewing Evolution of Learning Functions and Semantic Information Measures for Understanding Deep Learning](https://arxiv.org/pdf/2305.14397)
    16. Multi-Agent RL
        1.  [A Model-Based Solution to the Offline Multi-Agent Reinforcement Learning Coordination Problem](https://arxiv.org/pdf/2305.17198)
        2.  [Is Centralized Training with Decentralized Execution Framework Centralized Enough for MARL?](https://arxiv.org/pdf/2305.17352)
        3.  [Research on Multi-Agent Communication and Collaborative Decision-Making Based on Deep Reinforcement Learning](https://arxiv.org/pdf/2305.17141)
        4.  [Towards Efficient Multi-Agent Learning Systems](https://arxiv.org/pdf/2305.13411)
    17. Neural Networks
        1.  [Attention Schema in Neural Agents](https://arxiv.org/pdf/2305.17375)
        2.  [Augmented Random Search for Multi-Objective Bayesian Optimization of Neural Networks](https://arxiv.org/pdf/2305.14109)
        3.  [Deep Reinforcement Learning with Plasticity Injection](https://arxiv.org/pdf/2305.15555)
        4.  [Non-parametric, Nearest-neighbor-assisted Fine-tuning for Neural Machine Translation](https://arxiv.org/pdf/2305.13648)
    18. Offline RL
        1.  [MADiff: Offline Multi-agent Learning with Diffusion Models](https://arxiv.org/pdf/2305.17330)
        2.  [Matrix Estimation for Offline Reinforcement Learning with Low-Rank Structure](https://arxiv.org/pdf/2305.15621)
        3.  [Offline Experience Replay for Continual Offline Reinforcement Learning](https://arxiv.org/pdf/2305.13804)
        4.  [Offline Primal-Dual Reinforcement Learning for Linear MDPs](https://arxiv.org/pdf/2305.12944)
        5.  [Sequence Modeling is a Robust Contender for Offline Reinforcement Learning](https://arxiv.org/pdf/2305.14550)
    19. Online RL
        1.  [No-Regret Online Reinforcement Learning with Adversarial Losses and Transitions](https://arxiv.org/pdf/2305.17380)
        2.  [Online Nonstochastic Model-Free Reinforcement Learning](https://arxiv.org/pdf/2305.17552)
    20. Optimization
        1.  [Distributionally Robust Optimization Efficiently Solves Offline Reinforcement Learning](https://arxiv.org/pdf/2305.13289)
    21. Policy/Value Optimization
        1.  [Constrained Proximal Policy Optimization](https://arxiv.org/pdf/2305.14216)
        2.  [On the Value of Myopic Behavior in Policy Reuse](https://arxiv.org/pdf/2305.17623)
        3.  [Policy Representation via Diffusion Probability Model for Reinforcement Learning](https://arxiv.org/pdf/2305.13122)
    22. Reinforcement Learning from Human Preferences/Feedback
        1.  [Learning Interpretable Models of Aircraft Handling Behaviour by Reinforcement Learning from Human Feedback](https://arxiv.org/pdf/2305.16924)
        2.  [Provable Offline Reinforcement Learning with Human Feedback](https://arxiv.org/pdf/2305.14816)
        3.  [Query-Policy Misalignment in Preference-Based Reinforcement Learning](https://arxiv.org/pdf/2305.17400)
    23. Reward Optimization
        1.  [Video Prediction Models as Rewards for Reinforcement Learning](https://arxiv.org/pdf/2305.14343)
    24. Risk-sensitive/safe/constrained RL
        1.  [C-MCTS: Safe Planning with Monte Carlo Tree Search](https://arxiv.org/pdf/2305.16209)
        2.  [Control invariant set enhanced safe reinforcement learning: improved sampling efficiency, guaranteed stability and robustness](https://arxiv.org/pdf/2305.15602)
        3.  [GUARD: A Safe Reinforcement Learning Benchmark](https://arxiv.org/pdf/2305.13681)
        4.  [HJB based online safe reinforcement learning for state-constrained systems](https://arxiv.org/pdf/2305.12967)
        5.  [Inverse Preference Learning: Preference-based RL without a Reward Function](https://arxiv.org/pdf/2305.15363)
        6.  [Inverse Reinforcement Learning with the Average Reward Criterion](https://arxiv.org/pdf/2305.14608)
    25. Sample-efficiency
        1.  [Learning Better with Less: Effective Augmentation for Sample-Efficient Visual Reinforcement Learning](https://arxiv.org/pdf/2305.16379)
    26. Teacher-Student Framework
        1.  [Yes, this Way! Learning to Ground Referring Expressions into Actions with Intra-episodic Feedback from Supportive Teachers](https://arxiv.org/pdf/2305.12880)
    27. Text-to-image
        1.  [DPOK: Reinforcement Learning for Fine-tuning Text-to-Image Diffusion Models](https://arxiv.org/pdf/2305.16381)
    28. Theory of Information
        1.  [Reinforcement Learning with Simple Sequence Priors](https://arxiv.org/pdf/2305.17109)
    29. Transfer RL
        1.  [Collaborative World Models: An Online-Offline Transfer RL Approach](https://arxiv.org/pdf/2305.15260)
        2.  [PROTO: Iterative Policy Regularized Offline-to-Online Reinforcement Learning](https://arxiv.org/pdf/2305.15669)
    30. Transformers
        1.  [Emergent Agentic Transformer from Chain of Hindsight Experience](https://arxiv.org/pdf/2305.16554)
        2.  [End-to-End Meta-Bayesian Optimisation with Transformer Neural Processes](https://arxiv.org/pdf/2305.15930)
        3.  [Future-conditioned Unsupervised Pretraining for Decision Transformer](https://arxiv.org/pdf/2305.16683)
        4.  [Reinforcement Learning finetuned Vision-Code Transformer for UI-to-Code Generation](https://arxiv.org/pdf/2305.14637)
3.  __Recommender Systems__
    1. [Optimizing Long-term Value for Auction-Based Recommender Systems via On-Policy Reinforcement Learning](https://arxiv.org/pdf/2305.13747)
4.  __Financial Applications__
    1. [A Comparative Analysis of Portfolio Optimization Using Mean-Variance, Hierarchical Risk Parity, and Reinforcement Learning Approaches on the Indian Stock Market](https://arxiv.org/pdf/2305.17523)
    2. [Market Making with Deep Reinforcement Learning from Limit Order Books](https://arxiv.org/pdf/2305.15821)
5.  __Human-agent interaction__
    1. [A Hierarchical Approach to Population Training for Human-AI Collaboration](https://arxiv.org/pdf/2305.16708)
6.  __Games and Game Theory__
    1. [Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game](https://arxiv.org/pdf/2305.12872)
    2. [Deterministic Algorithmic Approaches to Solve Generalised Wordle](https://arxiv.org/pdf/2305.14756)
    3. [Ghost in the Minecraft: Generally Capable Agents for Open-World Enviroments via Large Language Models with Text-based Knowledge and Memory](https://arxiv.org/pdf/2305.17144)
    4.  [Know your Enemy: Investigating Monte-Carlo Tree Search with Opponent Models in Pommerman](https://arxiv.org/pdf/2305.13206)
    5.  [Lucy-SKG: Learning to Play Rocket League Efficiently Using Deep Reinforcement Learning](https://arxiv.org/pdf/2305.15801)
    6.  [Reinforcement Learning With Reward Machines in Stochastic Games](https://arxiv.org/pdf/2305.17372)
7.  __Physics__
    1.  [Physical Deep Reinforcement Learning: Safety and Unknown Unknowns](https://arxiv.org/pdf/2305.16614)"
8.  __Chemistry__
    1.  [ChemGymRL: An Interactive Framework for Reinforcement Learning for Digital Chemistry](https://arxiv.org/pdf/2305.14177)
    2.  [Probing reaction channels via reinforcement learning](https://arxiv.org/pdf/2305.17531)
9.  __Healthcare Applications__
    1.  [Control of a simulated MRI scanner with deep reinforcement learning](https://arxiv.org/pdf/2305.13979)
    2.  [HuatuoGPT, towards Taming Language Model to Be a Doctor](https://arxiv.org/pdf/2305.15075)
10. __Natural Language Processing__
    1.  [A Reminder of its Brittleness: Language Reward Shaping May Hinder Learning for Instruction Following Agents](https://arxiv.org/pdf/2305.16621)
    2.  [Aligning Large Language Models through Synthetic Feedback](https://arxiv.org/pdf/2305.13735)
    3.  [Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance](https://arxiv.org/pdf/2305.17306)
    4.  [ChatGPT: A Study on its Utility for Ubiquitous Software Engineering Tasks](https://arxiv.org/pdf/2305.16837)
    5.  [Gender Biases in Automatic Evaluation Metrics: A Case Study on Image Captioning](https://arxiv.org/pdf/2305.14711)
    6.  [Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation](https://arxiv.org/pdf/2305.15541)
    7.  [Improving Language Models with Advantage-based Offline Policy Gradients](https://arxiv.org/pdf/2305.14718)
    8.  [Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning](https://arxiv.org/pdf/2305.15065)
    9.  [Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback](https://arxiv.org/pdf/2305.14975)
    10. [Language Model Self-improvement by Reinforcement Learning Contemplation](https://arxiv.org/pdf/2305.14483)
    11. [Mindstorms in Natural Language-Based Societies of Mind](https://arxiv.org/pdf/2305.17066)
    12. [Modeling Adversarial Attack on Pre-trained Language Models as Sequential Decision Making](https://arxiv.org/pdf/2305.17440)
    13. [On the Correspondence between Compositionality and Imitation in Emergent Neural Communication](https://arxiv.org/pdf/2305.12941)
    14. [Query Rewriting for Retrieval-Augmented Large Language Models](https://arxiv.org/pdf/2305.14283)
    15. [SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and Reasoning](https://arxiv.org/pdf/2305.15486)
11. __Mathematics__
    1.  [Decomposing the Enigma: Subgoal-based Demonstration Learning for Formal Theorem Proving](https://arxiv.org/pdf/2305.16366)
    2.  [RetICL: Sequential Retrieval of In-Context Examples with Reinforcement Learning](https://arxiv.org/pdf/2305.14502)
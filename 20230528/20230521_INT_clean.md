# Notes on RL 19

1.  [Replicable Reinforcement Learning](https://arxiv.org/pdf/2305.15284) INT INT
2.  [Learning to Act through Evolution of Neural Diversity in Random Neural Networks](https://arxiv.org/pdf/2305.15945) INT
3.  [Self-Supervised Reinforcement Learning that Transfers using Random Features](https://arxiv.org/pdf/2305.17250) INT
4.  [Towards Efficient Multi-Agent Learning Systems](https://arxiv.org/pdf/2305.13411) INT
5. [A Hierarchical Approach to Population Training for Human-AI Collaboration](https://arxiv.org/pdf/2305.16708) INT
6. [Know your Enemy: Investigating Monte-Carlo Tree Search with Opponent Models in Pommerman](https://arxiv.org/pdf/2305.13206) INT
7.  [A Reminder of its Brittleness: Language Reward Shaping May Hinder Learning for Instruction Following Agents](https://arxiv.org/pdf/2305.16621) INT
8.  [Aligning Large Language Models through Synthetic Feedback](https://arxiv.org/pdf/2305.13735) INT
9.  [Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance](https://arxiv.org/pdf/2305.17306) INT
10. [Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback](https://arxiv.org/pdf/2305.14975) INT
11. [Language Model Self-improvement by Reinforcement Learning Contemplation](https://arxiv.org/pdf/2305.14483) INT INT
12. [Mindstorms in Natural Language-Based Societies of Mind](https://arxiv.org/pdf/2305.17066) INT INT
13. [Query Rewriting for Retrieval-Augmented Large Language Models](https://arxiv.org/pdf/2305.14283) INT
14. [SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and Reasoning](https://arxiv.org/pdf/2305.15486) INT
15. [Decomposing the Enigma: Subgoal-based Demonstration Learning for Formal Theorem Proving](https://arxiv.org/pdf/2305.16366) INT
16. [RetICL: Sequential Retrieval of In-Context Examples with Reinforcement Learning](https://arxiv.org/pdf/2305.14502) INT
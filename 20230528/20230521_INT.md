# Notes on RL 19

4.  [Communication-Efficient Reinforcement Learning in Swarm Robotic Networks for Maze Exploration](https://arxiv.org/pdf/2305.17087) INT
1.  [Replicable Reinforcement Learning](https://arxiv.org/pdf/2305.15284) INT INT
2.  [Testing of Deep Reinforcement Learning Agents with Surrogate Models](https://arxiv.org/pdf/2305.12751) INT
1.  [Learning to Act through Evolution of Neural Diversity in Random Neural Networks](https://arxiv.org/pdf/2305.15945) INT
2.  [Self-Supervised Reinforcement Learning that Transfers using Random Features](https://arxiv.org/pdf/2305.17250) INT
4.  [Towards Efficient Multi-Agent Learning Systems](https://arxiv.org/pdf/2305.13411) INT
1. [A Hierarchical Approach to Population Training for Human-AI Collaboration](https://arxiv.org/pdf/2305.16708) INT
4. [Know your Enemy: Investigating Monte-Carlo Tree Search with Opponent Models in Pommerman](https://arxiv.org/pdf/2305.13206) INT
1.  [A Reminder of its Brittleness: Language Reward Shaping May Hinder Learning for Instruction Following Agents](https://arxiv.org/pdf/2305.16621) INT
2.  [Aligning Large Language Models through Synthetic Feedback](https://arxiv.org/pdf/2305.13735) INT
3.  [Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance](https://arxiv.org/pdf/2305.17306) INT
4.  [ChatGPT: A Study on its Utility for Ubiquitous Software Engineering Tasks](https://arxiv.org/pdf/2305.16837) INT
6.  [Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation](https://arxiv.org/pdf/2305.15541) INT
9.  [Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback](https://arxiv.org/pdf/2305.14975) INT
10. [Language Model Self-improvement by Reinforcement Learning Contemplation](https://arxiv.org/pdf/2305.14483) INT INT
11. [Mindstorms in Natural Language-Based Societies of Mind](https://arxiv.org/pdf/2305.17066) INT INT
12. [Modeling Adversarial Attack on Pre-trained Language Models as Sequential Decision Making](https://arxiv.org/pdf/2305.17440) INT INT
14. [Query Rewriting for Retrieval-Augmented Large Language Models](https://arxiv.org/pdf/2305.14283) INT
15. [SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and Reasoning](https://arxiv.org/pdf/2305.15486) INT
1.  [Decomposing the Enigma: Subgoal-based Demonstration Learning for Formal Theorem Proving](https://arxiv.org/pdf/2305.16366) INT
2.  [RetICL: Sequential Retrieval of In-Context Examples with Reinforcement Learning](https://arxiv.org/pdf/2305.14502) INT
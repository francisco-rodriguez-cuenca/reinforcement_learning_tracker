The field of AI alignment is one of the most critical and challenging areas of artificial intelligence research. The question of how to ensure that AI systems are aligned with human values and amenable to human control is at the heart of this field. But is there something special about AI that makes questions about value alignment more complicated or acute?

From a normative perspective, we are able to encode a richer set of values in AI systems than in simpler artifacts. From a technological perspective, the greater scope of action and intelligence of AI systems creates new challenges from the perspectives of alignment and control.

In this blog post, we will explore the concept of value alignment, the potential uniqueness of AI systems, and the technical approaches to value alignment. We will also delve into the fundamental relevance of value in AI and the importance of thinking about these issues early on.

First, let's define what we mean by value. According to Friedman and Henry, value from a technological perspective is "what is important to people in their lives, with a focus on ethics and morality." This includes issues such as social justice, privacy, and safety.

But do artifacts, such as technologies, have politics? Landgdon Winner argues that they do. For example, the design of bridges in New York City by Robert Moses limited transport flows from poor to nice neighborhoods, while Baron Haussman's redesign of the streets of Paris after the French revolution facilitated troop movement and suppressed the possibility of protest. Technologies can draw forth certain modes of social organization and the need for large datasets and computer power favors centralized forms of political authority and governance.

It's important to note that there is no such thing as a value-neutral technology. New technologies make some outcomes more likely and some outcomes less likely to occur, they create new possibilities and sometimes exclude certain possibilities to be realized. As technologists, we are engaged in a world-making activity, and there is a level of responsibility to ensure that our technology aligns with human values (both personal and social). Key methods for value alignment include stakeholder analysis and citizen consultation.

Now, let's delve into the potential uniqueness of AI systems. AI is defined as machines that are intelligent to the extent that their actions can be expected to match their objectives. Machine learning, a family of statistical and algorithmic approaches, is one of the most promising fields of AI research. However, it also presents challenges such as algorithmic bias and social value misalignment. For example, algorithms in the criminal justice system, healthcare, and facial analysis have been found to discriminate against women and non-white people.

Daniel Dennett's concept of degrees of freedom is also relevant here. Simple switches that can be turned on/off by some environmental change marks a degree of freedom. However, biological organisms, humans, and networks have additional degrees of freedom, and issues of control become complex and non-linear. Artificial agents can learn new mappings between inputs and outputs, coming up with results that surprise their human creators.

To ensure that AI systems are aligned with human values, a range of technical approaches have been proposed. These include top-down and bottom-up approaches, as well as addressing specific problems such as algorithmic bias. For highly advanced AI, the alignment problem becomes even more challenging and requires novel solutions.

In conclusion, the challenge of AI alignment is a critical and complex issue that requires the attention of technologists, ethicists, and policymakers. As we continue to develop AI systems, we must consider the fundamental relevance of value and work towards ensuring that our technology aligns with human values and is amenable to human control. By thinking about these issues early on and engaging in stakeholder analysis and citizen consultation, we can create a more just and equitable society.

# V2

In this paper, Iason Gabriel and Vafa Ghazavi address the critical challenge of AI alignment. The authors argue that ensuring AI systems are aligned with human values and amenable to human control is at the heart of this field. They explore the concept of value alignment and the potential uniqueness of AI systems, as well as the technical approaches to value alignment.

The authors define value from a technological perspective as "what is important to people in their lives, with a focus on ethics and morality." They also discuss the idea that technologies have politics and the importance of thinking about these issues early on.

In terms of the potential uniqueness of AI systems, the authors note that while machine learning presents many opportunities, it also presents challenges such as algorithmic bias and social value misalignment. They also discuss the concept of degrees of freedom in relation to AI and the increasing complexity of the alignment problem as AI systems become more advanced.

The authors propose a range of technical approaches to address these challenges, including top-down and bottom-up approaches, as well as addressing specific problems such as algorithmic bias.

Overall, Gabriel and Ghazavi argue that the challenge of AI alignment is a critical and complex issue that requires the attention of technologists, ethicists, and policymakers. They stress the importance of considering the fundamental relevance of value and working towards ensuring that AI aligns with human values and is amenable to human control.
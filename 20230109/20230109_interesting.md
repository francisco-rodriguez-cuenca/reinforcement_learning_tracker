# 2nd week of the year

## Things to read

* The Challenge of Value Alignment: from Fairer Algorithms to AI Safety
* [Introduction to Graph Machine Learning](https://huggingface.co/blog/intro-graphml?utm_source=substack&utm_medium=email#introduction-to-graph-machine-learning)

## New papers

1. Engineering Applications
   1. [Safe Reinforcement Learning for an Energy-Efficient Driver Assistance System](https://arxiv.org/pdf/2301.00904.pdf)
      1. Application of RL techniques in safety-critical systems like vehicle control
      2. VERY INTERESTING
   2. [Safety Filtering for Reinforcement Learning-based Adaptive Cruise Control](https://arxiv.org/pdf/2301.00884.pdf)
      1. Same as previous
      2. VERY Interesting
   3.  [Physics-Informed Model-Based Reinforcement Learning](https://arxiv.org/pdf/2212.02179.pdf)
       1.  Very interesting
       2.  v3
       3.  Improve sample efficiency through physics analysis of the environment
   4.  [Implementing Reinforcement Learning Datacenter Congestion Control in NVIDIA NICs](https://arxiv.org/pdf/2207.02295.pdf)
       1.  Congestion control in datacenters via RL
       2.  Interesting and Important (NVIDIA)
2.  RL + Genetic Algorthms
   1.  [RL-GA: A Reinforcement Learning-Based Genetic Algorithm for Electromagnetic Detection Satellite Scheduling Problem](https://arxiv.org/pdf/2206.05694.pdf)
       1.  To learn
3. Reinforcement Learning Theory
   1. [Provable Reset-free Reinforcement Learning by No-Regret Reduction](https://arxiv.org/pdf/2301.02389.pdf)
      1. typical RL algorithms heavily rely on the reset mechanism to sample proper initial states -> expensive
      2. proposes a generic no-regret reduction to systematically design reset-free RL algorithms
      3. VERY INTERESTING
   2. [Chat2Map: Efficient Scene Mapping from Multi-Ego Conversations](https://arxiv.org/pdf/2301.02184.pdf)
      1. Map a scene using multi-ego conversations
      2. VERY INTERESTING
   3. [Self-Motivated Multi-Agent Exploration](https://arxiv.org/pdf/2301.02083.pdf)
      1.  We propose Self-Motivated Multi-Agent Exploration (SMMAE), which aims to achieve success in team tasks by adaptively finding a trade-off between self-exploration and team cooperation.
      2.  VERY INTERESTING
   4.  [Data-Driven Inverse Reinforcement Learning for Expert-Learner Zero-Sum Games](https://arxiv.org/pdf/2301.01997.pdf)
       1.  Add non-cooperative disturbances Inverse RL to disrupt the learning and stability of the learner agent and generate Zero-Sum Games
       2.  VERY INTERESTING
   5.  [Towards Deployable RL - Whatâ€™s Broken with RL Research and a Potential Fix](https://arxiv.org/pdf/2301.01320.pdf)
       1.  MUST READ
   6.  [Offline Evaluation for Reinforcement Learning-based Recommendation: A Critical Issue and Some Alternatives](https://arxiv.org/pdf/2301.00993.pdf)
       1.  The paradigm commonly adopted for offline evaluation of sequential recommender systems is unsuitable for evaluating reinforcement learning-based recommenders
       2.  VERY INTERESTING
   7.  [Second Thoughts are Best: Learning to Re-Align With Human Values from Text Edits](https://arxiv.org/pdf/2301.00355.pdf)
       1.  MUST READ
   8.  [First Go, then Post-Explore: the Benefits of Post-Exploration in Intrinsic Motivation](https://arxiv.org/pdf/2212.03251.pdf)
       1.  Exploration method
       2.  Interesting
   9.  [Hypernetworks for Zero-shot Transfer in Reinforcement Learning](https://arxiv.org/pdf/2211.15457.pdf)
       1.  uuuuu hypernetworks and temporal difference learning
       2.  meta-RL, contextual RL and transfer learning
       3.  Interesting to learn about this kind of stuff
   10. [Solving Collaborative Dec-POMDPs with Deep Reinforcement Learning Heuristics](https://arxiv.org/pdf/2211.15411.pdf)
       1.  Isn't it clear?
       2. To learn
    11. [Phantom - A RL-driven multi-agent framework to model complex systems](https://arxiv.org/pdf/2210.06012.pdf)
        1.  Open-source framework to unite Agent Based Modelling and Multi-Agent Reinforcement Learning
        2.  Interesting
    12. [Reinforcement Learning With Sparse-Executing Actions via Sparsity Regularization](https://arxiv.org/pdf/2105.08666.pdf)
       1.  Interesting, sparsity is a big problem
       2.  For problems with few resources
4. Financial Applications
   1. [Deep Reinforcement Learning in a Monetary Model](https://arxiv.org/pdf/2104.09368.pdf)
      1. We apply our proposed approach to a classical model from the adaptive learning literature in macroeconomics which looks at the interaction of monetary and fiscal policy.
      2. We find that, contrary to adaptive learning, the artificially intelligent household can solve the model in all policy regimes
      3. Very interesting
5. Game Theory
   1. [Emergent collective intelligence from massive-agent cooperation and competition](https://arxiv.org/pdf/2301.01609.pdf)
      1. VERY INTERESTING
      2. We study the emergence of artificial collective intelligence through massive-agent reinforcement learning
   2. [Start Small: Training Controllable Game Level Generators without Training Data by Learning at Multiple Sizes](https://arxiv.org/pdf/2209.15052.pdf)
      1. Very interesting
      2. Creating Game Level Generators from Noise
   3. [A General Framework for Learning Mean-Field Games](https://arxiv.org/pdf/2003.06069.pdf)
      1. Naively combining reinforcement learning with the fixed-point approach in classical Mean Field Games yields unstable algorithms. 
      2. Proposes specific novel algorithms 
      3. Interesting
6. JUST CREEPY
   1. [Robofriend: An Adpative Storytelling Robotic Teddy Bear -- Technical Report](https://arxiv.org/pdf/2301.01576.pdf)
      1. MUST READ
   2. [e-Inu: Simulating A Quadruped Robot With Emotional Sentience](https://arxiv.org/pdf/2301.00964.pdf)
      1. MUST-READ
7.  Reviews
   1. [A Succinct Summary of Reinforcement Learning](https://arxiv.org/pdf/2301.01379.pdf)
      1. The intended audience are those who already have some familiarity with RL and are looking to review, reference and/or remind themselves of important ideas in the field.
      2. VERY INTERESTING
8.  Human Agent Cooperation
    1.  [Interpretable Learned Emergent Communication for Human-Agent Teams](https://arxiv.org/pdf/2201.07452.pdf)
        1.  MUST READ
        2.  we analyze the efficacy of sparse-discrete methods for producing emergent communication that enables high agent-only and human-agent team s